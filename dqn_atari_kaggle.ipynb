{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oV5G7nvkiA1J"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHbGUTUWtEaN"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade ale-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install minari\n",
    "!pip install --upgrade gymnasium \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsdmHJhug3cH"
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "import minari\n",
    "import random\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXx6nCyr1-Zq"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShEz7Zn4kvtN"
   },
   "outputs": [],
   "source": [
    "!mkdir videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYVbjNUThYKE"
   },
   "outputs": [],
   "source": [
    "env = gym.make('BreakoutNoFrameskip-v4', obs_type='rgb', render_mode='rgb_array')\n",
    "env = gym.wrappers.AtariPreprocessing(env, grayscale_obs=True, frame_skip=4, terminal_on_life_loss=True, scale_obs=True)\n",
    "env = gym.wrappers.RecordVideo(env, video_folder=\"videos/\", name_prefix=\"breakout_test\")\n",
    "env = gym.wrappers.FrameStackObservation(env, 4)  # stack 4 consecutive frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ogKer1pq14x"
   },
   "outputs": [],
   "source": [
    "obs, info = env.reset()\n",
    "frames = [obs]\n",
    "\n",
    "total_reward = 0\n",
    "for step in range(10):\n",
    "    action = env.action_space.sample()  # random action\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n",
    "\n",
    "    for i in range(4):\n",
    "        axes[i].imshow(obs[i, :, :], cmap='gray')\n",
    "        axes[i].set_title(f'Step {step+1}, Frame {i+1}')\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    frames.append(obs)\n",
    "    total_reward += reward\n",
    "    if done or truncated:\n",
    "        break\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L33VHztTs6P8"
   },
   "source": [
    "#SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKxbPfilv37A"
   },
   "outputs": [],
   "source": [
    "class MinariDataset(Dataset):\n",
    "    def __init__(self, dataset, stack_size=4):\n",
    "        # obs\n",
    "        obs = np.concatenate([ep.observations for ep in dataset], axis=0)\n",
    "        obs = np.array([cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) for frame in obs], dtype=np.float32)\n",
    "        obs = np.array([cv2.resize(frame, (84, 84)) for frame in obs], dtype=np.float32)\n",
    "        obs = obs / 255.0\n",
    "        obs = (obs > 0.1).astype(np.float32)\n",
    "        obs = (obs - 0.5) * 2\n",
    "\n",
    "        obs = obs[:,8:,:]\n",
    "        obs = obs[:,:,4:80]\n",
    "\n",
    "        obs[:,:8,:] = 0.5\n",
    "\n",
    "        self.obs = obs\n",
    "\n",
    "        # diffs\n",
    "        diffs = (obs[1:] - obs[:-1])/2\n",
    "        self.diffs = diffs\n",
    "\n",
    "        # ball position\n",
    "\n",
    "        h,w = obs.shape[1:]\n",
    "        ds = diffs.copy()\n",
    "        ds[:, 67:70, :] = 0.0\n",
    "        ball_pos = np.zeros((obs.shape[0], 2), dtype=np.float32)\n",
    "\n",
    "        for i in range(obs.shape[0]):\n",
    "            cond = (ds[max(0,i-1),:,:] == 1) | (ds[min(obs.shape[0]-2,i),:,:] == -1)\n",
    "            idx = np.argwhere(cond)\n",
    "            if len(idx) > 0:\n",
    "                ball_pos[i, 0] = idx[:, 0].mean() / h\n",
    "                ball_pos[i, 1] = idx[:, 1].mean() / w\n",
    "\n",
    "        self.ball_pos = ball_pos\n",
    "\n",
    "        self.stack_size = stack_size\n",
    "        self.max_idx = len(self.obs) - stack_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.max_idx\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "          # --- Target ---\n",
    "          stack = self.obs[idx : idx + self.stack_size].copy()  # (stack_size, H, W)\n",
    "          target = torch.tensor(stack, dtype=torch.float32)\n",
    "\n",
    "          # --- Input ---\n",
    "          drop_idx = random.randint(0, self.stack_size - 1)\n",
    "          masked_stack = stack.copy()\n",
    "          masked_stack[drop_idx] = 0.0\n",
    "          x = torch.tensor(masked_stack, dtype=torch.float32)\n",
    "\n",
    "          # --- Diff ---\n",
    "          # differences between consecutive frames: (stack_size-1, H, W)\n",
    "          diff_stack = self.diffs[idx : idx + self.stack_size - 1].copy()\n",
    "          diff_stack = torch.tensor(diff_stack, dtype=torch.float32)\n",
    "\n",
    "          # --- ball position ---\n",
    "          # ball position\n",
    "          ball_pos = self.ball_pos[idx : idx + self.stack_size].copy()\n",
    "          ball_pos = torch.tensor(ball_pos, dtype=torch.float32)\n",
    "\n",
    "\n",
    "          return x, target, diff_stack, ball_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAdwTQ6OzDRp"
   },
   "outputs": [],
   "source": [
    "minari_dataset = minari.load_dataset('atari/breakout/expert-v0', download=True)\n",
    "minari_dataset = MinariDataset(dataset = minari_dataset)\n",
    "minari_dataloader = DataLoader(minari_dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZH2eTzXuYMq"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_channels=4, latent_dim=128):\n",
    "        super().__init__()\n",
    "        # --- Encoder ---\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=8, stride=4)  # -> (32, 18, 18)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)             # -> (64, 8, 8)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)             # -> (64, 6, 6)\n",
    "        self.fc1 = nn.Linear(6*6*64, latent_dim)\n",
    "\n",
    "        # --- Decoder ---\n",
    "        self.fc2 = nn.Linear(latent_dim, 6*6*64)\n",
    "        self.deconv1 = nn.ConvTranspose2d(64, 64, kernel_size=3, stride=1)  # -> (64, 8, 8)\n",
    "        self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2)  # -> (32, 18, 18)\n",
    "        self.deconv3 = nn.ConvTranspose2d(32, input_channels, kernel_size=8, stride=4)  # -> (4, 84, 84)\n",
    "\n",
    "        # --- Difference Decoder ---\n",
    "        # Predicts (stack_size-1) difference frames per input stack\n",
    "        self.diff_fc2 = nn.Linear(latent_dim, 64*6*6)\n",
    "        self.diff_deconv1 = nn.ConvTranspose2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.diff_deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2)\n",
    "        self.diff_deconv3 = nn.ConvTranspose2d(32, input_channels-1, kernel_size=8, stride=4)\n",
    "\n",
    "        # --- Ball Position Decoder (2×4) ---\n",
    "        self.ball_fc = nn.Linear(latent_dim, 8)  # → 8 numbers: 2 rows × 4 columns\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # --- Encoder ---\n",
    "        x_enc = F.leaky_relu(self.conv1(x))\n",
    "        x_enc = F.leaky_relu(self.conv2(x_enc))\n",
    "        x_enc = F.leaky_relu(self.conv3(x_enc))\n",
    "        x_enc_flat = x_enc.view(x_enc.size(0), -1)\n",
    "        latent = F.leaky_relu(self.fc1(x_enc_flat))\n",
    "\n",
    "        # --- Full-frame Decoder ---\n",
    "        x_dec = F.leaky_relu(self.fc2(latent))\n",
    "        x_dec = x_dec.view(x_dec.size(0), 64, 6, 6)\n",
    "        x_dec = F.leaky_relu(self.deconv1(x_dec))\n",
    "        x_dec = F.leaky_relu(self.deconv2(x_dec))\n",
    "        recon_full = torch.tanh(self.deconv3(x_dec))  # (B, 4, H, W)\n",
    "\n",
    "        # --- Difference Decoder ---\n",
    "        d_dec = F.leaky_relu(self.diff_fc2(latent))\n",
    "        d_dec = d_dec.view(d_dec.size(0), 64, 6, 6)\n",
    "        d_dec = F.leaky_relu(self.diff_deconv1(d_dec))\n",
    "        d_dec = F.leaky_relu(self.diff_deconv2(d_dec))\n",
    "        recon_diff = torch.tanh(self.diff_deconv3(d_dec))  # (B, 3, H, W)  (stack_size-1)\n",
    "\n",
    "        # --- Ball Position Head ---\n",
    "        ball_raw = torch.sigmoid(self.ball_fc(latent))        # (B, 8)\n",
    "        ball_pos = ball_raw.view(-1, 4, 2)           # (B, 2, 4)\n",
    "\n",
    "\n",
    "        return recon_full, recon_diff, ball_pos, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUDMxcFX1vkt"
   },
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()\n",
    "autoencoder = autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WP3GO3vrsxKJ"
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"/kaggle/input/asdfghj/autoencoder_6.pth\", map_location=device)\n",
    "autoencoder.load_state_dict(state_dict, strict=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58uj7PY22Vre"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(autoencoder.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wNSZwaheOsl"
   },
   "outputs": [],
   "source": [
    "num_epochs = 1001\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "    autoencoder.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for input, target, diff_target, pos_target  in tqdm(minari_dataloader,leave=False):\n",
    "\n",
    "        input, target, diff_target, pos_target = input.to(device), target.to(device), diff_target.to(device), pos_target.to(device)\n",
    "\n",
    "        # --- Forward pass ---\n",
    "        recon, recon_diff, recon_pos, _ = autoencoder(input)\n",
    "\n",
    "        # --- Loss computation ---\n",
    "        # Full-stack reconstruction\n",
    "        loss = F.mse_loss(recon, target)\n",
    "\n",
    "        # Difference prediction with weighted loss\n",
    "\n",
    "        weight_diff = (diff_target != 0).float()\n",
    "\n",
    "        ball_mask = torch.zeros_like(weight_diff)\n",
    "        ball_mask[:, :, 29:67, :] = 1.0\n",
    "        ball_mask[:, :, 9:15, :] = 1.0\n",
    "\n",
    "        weight_diff = weight_diff + 10 * weight_diff * ball_mask\n",
    "        weight_diff = weight_diff + 0.01\n",
    "\n",
    "        weight_diff = weight_diff / weight_diff.sum()\n",
    "\n",
    "\n",
    "        loss_diff = ((recon_diff - diff_target)**2 * weight_diff).sum()\n",
    "\n",
    "        # Ball position prediction\n",
    "        loss_pos = F.mse_loss(recon_pos, pos_target)\n",
    "\n",
    "        # Total loss\n",
    "        loss = loss + loss_diff + loss_pos\n",
    "\n",
    "        # --- Backprop ---\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * input.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(minari_dataloader.dataset)\n",
    "    print(f\"Epoch {epoch:03d} | Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # --- Visualization / checkpointing ---\n",
    "    if epoch % 50 == 0 or (epoch in [5, 10]):\n",
    "\n",
    "        torch.save(autoencoder.state_dict(), f\"autoencoder_{epoch:03d}.pth\")\n",
    "\n",
    "        shards = {\"Input\": input,\n",
    "          \"Target\": target,\n",
    "          \"Recon\": recon,\n",
    "          \"Diff_Target\": diff_target,\n",
    "          \"Weight-Diff\": weight_diff,\n",
    "          \"Recon_Diff\": recon_diff\n",
    "        }\n",
    "\n",
    "        for key, value in shards.items():\n",
    "\n",
    "          shard = value[0].cpu().detach().numpy()\n",
    "\n",
    "          fig, axes = plt.subplots(1, shard.shape[0], figsize=(9, 3))\n",
    "          for i in range(shard.shape[0]):\n",
    "              axes[i].imshow(shard[i], cmap='gray')\n",
    "              axes[i].set_title(f'{key} - Frame {i+1}')\n",
    "              axes[i].axis('off')\n",
    "          plt.show()\n",
    "\n",
    "        print(f\"Pos Target: {pos_target[0]}\")\n",
    "        print(f\"Recon Pos: {recon_pos[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "num_samples = 5  # number of samples to visualize\n",
    "sample_indices = random.sample(range(len(minari_dataset)), num_samples)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    input, target, diff_target, pos_target = minari_dataset[idx]\n",
    "\n",
    "    # Add batch dimension and move to device\n",
    "    input = input.unsqueeze(0).to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        recon, recon_diff,recon_pos, _ = autoencoder(input)\n",
    "\n",
    "    # Move tensors back to CPU for plotting\n",
    "    input_np = input[0].cpu().numpy()\n",
    "    target_np = target.cpu().numpy()\n",
    "    recon_np = recon[0].cpu().numpy()\n",
    "    diff_target_np = diff_target.cpu().numpy()\n",
    "    recon_diff_np = recon_diff[0].cpu().numpy()\n",
    "\n",
    "    # --- Plot ---\n",
    "    shards = {\n",
    "        \"Input\": input_np,\n",
    "        \"Target\": target_np,\n",
    "        \"Recon\": recon_np,\n",
    "        \"Diff_Target\": diff_target_np,\n",
    "        \"Recon_Diff\": recon_diff_np\n",
    "    }\n",
    "\n",
    "    for key, value in shards.items():\n",
    "        fig, axes = plt.subplots(1, value.shape[0], figsize=(9, 3))\n",
    "        for i in range(value.shape[0]):\n",
    "            axes[i].imshow(value[i], cmap='gray')\n",
    "            axes[i].set_title(f'{key} - Frame {i+1}')\n",
    "            axes[i].axis('off')\n",
    "        plt.suptitle(f'Sample {idx} - {key}')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    print(f\"Pos Target: {pos_target}\")\n",
    "    print(f\"Pos Recon: {recon_pos}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8735994,
     "sourceId": 13730745,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
